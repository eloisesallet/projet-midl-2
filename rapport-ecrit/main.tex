\documentclass{article}
\usepackage{bbm}
\usepackage[utf8]{inputenc}
\usepackage[T1]{fontenc}
\usepackage[french]{babel}
\usepackage{graphicx}
\usepackage{geometry}
\usepackage{fancyhdr}
\usepackage{hyperref}
\usepackage{xcolor}
\usepackage{caption}
\usepackage{titlesec}
\usepackage{float}
\usepackage{amsmath,amssymb}
\usepackage{lmodern}
\usepackage{listings}

\lstset{ 
  language=Python,
  basicstyle=\ttfamily\small,
  backgroundcolor=\color{gray!10},
  frame=single,
  rulecolor=\color{black},
  breaklines=true,
  captionpos=b
  inputencoding=utf8, % Permet d'utiliser les accents
  extendedchars=true 
}

\geometry{a4paper, margin=2.5cm}

% Mise en forme des entêtes et pieds de page
\pagestyle{fancy}
\fancyhf{}
\fancyhead[L]{\leftmark}
\fancyhead[R]{\thepage}

% Couleurs pour listings
\definecolor{codegray}{gray}{0.95}

\lstset{
  backgroundcolor=\color{codegray},
  basicstyle=\ttfamily\small,
  frame=single,
  breaklines=true,
  tabsize=2,
  language=Python, % à adapter selon ton code
  captionpos=b
}

% Page de garde
\begin{document}
\begin{titlepage}
    \centering
    \vspace*{1cm}

    % Logo avec taille réduite
    \includegraphics[width=0.4\textwidth]{universite-de-toulouse-2023-logo-png_seeklogo-469435.png} 

    \vspace{1.5cm}

    % Titre principal
    {\LARGE \textbf{Projet MIDL 2}}\\[0.5cm]

    % Auteurs
    {\large
        CROS Héléna\\
        HO Sylvie\\
        LORY Solène\\
        SALLET Eloïse
    }

    \vfill

    % Texte de bas de page, centré
    {\large
        Projet de la double licence mathématiques et informatique\\
        Janvier 2026
    }

\end{titlepage}

% Table des matières
\tableofcontents

\newpage

\section{Introduction}

\subsection{Choix du sujet d'étude}
Le choix du vidéo vient de l'un des modèles de reconnaissance de mouvement les plus connus du grand public : la licence de jeux "Just Dance". Actuellement, le score calculé en jeu se base uniquement sur le mouvement d'une manette tenue en main, et ne prend donc pas en compte l’entièreté des mouvements du corps. Dans un récent article, Ubisoft déclare que les futurs jeux pourront utiliser la caméra du téléphone afin d'avoir une reconnaissance totale du corps. 

En utilisant MMPose, nous allons tenter de reconnaître les répétitions d'une danse volontairement choisie répétitive et donc tenter de prédire la suite de la danse. Nous avons choisit la chorégraphie faite par la licence sur "Walk Like an Egyptian" de The Bangles pour ses mouvements répétitifs et clairs (la danse de l’égyptien tentant de reproduire les motifs des hiéroglyphes en 2D, le mouvement est très clair sur une vidéo elle même en 2D).

\subsection{Choix du modèle}
Les environnements respectifs de nos machines nous ont poussé à choisir le modèle MMPose Inferencer, à savoir le modèle le plus classique. En effet, 3 d'entre nous ne possèdent pas de composantes Nvidia, ce qui nous pousse à tourner sous CPU et non sous GPU, baissant drastiquement les capacités de nos machines sur ce modèle précis. Nous nous sommes ainsi tournées vers les modèles de la librairie les plus classiques afin de tenter de réduire le temps d’exécution du modèle, déjà élevé.




\subsection{Approche Méthodologique}
Notre démarche repose sur une chaîne de traitement complète (\textit{pipeline}) alliant extraction de données et Deep Learning :

\begin{itemize}
    \item \textbf{L'Extraction de Pose (\textit{Pose Estimation}) :} Utilisation de la librairie MMPose pour transformer les pixels de la vidéo brute en squelettes numériques (coordonnées $x, y$ des articulations).
    \item \textbf{La Modélisation Temporelle :} Entraînement d'un réseau de neurones récurrents LSTM (\textit{Long Short-Term Memory}), choisi pour sa capacité à retenir l'historique des mouvements passés afin de prédire les mouvements futurs.
    \item \textbf{La Génération Créative :} Développement d'un algorithme de génération incluant un "Mode Miroir" pour complexifier la danse et éviter la simple mémorisation.
\end{itemize}

Ce rapport détaille les étapes techniques de cette réalisation, analyse les performances du modèle à travers des métriques quantitatives (Score $R^2$) et qualitatives (visualisation 3D), et discute des défis rencontrés, notamment la stabilité anatomique du squelette généré.
\newpage


\section{Méthodologie}

Cette section détaille l'architecture technique mise en œuvre pour passer d'une vidéo brute à un modèle génératif capable de prédire des mouvements. Notre approche se décompose en trois phases : l'extraction de pose, le prétraitement des données et la modélisation par réseau de neurones récurrents.

\subsection{Acquisition et Extraction des Données (MMPose)}
La première étape consiste à numériser le mouvement humain. Pour cela, nous avons utilisé la librairie **MMPose** (basée sur le framework OpenMMLab), reconnue pour sa robustesse et sa rapidité d'inférence.

Nous avons utilisé un modèle pré-entraîné sur le dataset COCO (Common Objects in Context), capable de détecter 17 points clés (\textit{keypoints}) sur le corps humain.
\begin{itemize}
    \item \textbf{Entrée :} Une séquence vidéo de la "Danse de l'Égyptien".
    \item \textbf{Processus :} Pour chaque image (\textit{frame}) de la vidéo, le modèle inferentiel détecte la présence humaine et localise les articulations avec un score de confiance.
    \item \textbf{Sortie :} Une matrice de dimension $(N, 17, 2)$, où $N$ est le nombre total de frames, 17 le nombre d'articulations, et 2 les coordonnées $(x, y)$ dans l'espace de l'image.
\end{itemize}

Ce choix technique est pertinent pour la Danse de l'Égyptien car MMPose est particulièrement précis sur les membres supérieurs (coudes, poignets, épaules), qui sont les éléments centraux de cette chorégraphie géométrique.

\subsection{Prétraitement et Normalisation}
Les données brutes issues de MMPose ne sont pas directement exploitables pour l'apprentissage. Si le danseur se déplace de gauche à droite, les coordonnées changent drastiquement même si le mouvement intrinsèque (ex: plier le bras) reste le même. Nous avons donc appliqué deux transformations majeures :

\begin{enumerate}
    \item \textbf{Centrage Relatif (Invariance Spatiale) :} 
    Nous avons défini le point médian des hanches comme l'origine $(0,0)$ du repère. À chaque frame, toutes les coordonnées sont recalculées relativement à ce centre. Cela permet au modèle d'apprendre la \textit{posture} du danseur indépendamment de sa position dans la pièce.
    
    \item \textbf{Séquençage (Fenêtre Glissante) :}
    Les réseaux de neurones ne peuvent pas traiter une vidéo entière d'un coup. Nous avons structuré les données en fenêtres glissantes (\textit{sliding windows}).
    \begin{itemize}
        \item \textit{Input ($X$)} : Une séquence de $T$ frames (historique).
        \item \textit{Target ($Y$)} : La frame $T+1$ (le futur immédiat à prédire).
    \end{itemize}
\end{enumerate}

Cette structuration transforme le problème de génération en un problème d'apprentissage supervisé classique.

\subsection{Architecture du Modèle (LSTM)}
La danse étant par nature une série temporelle (chaque mouvement dépend des précédents), nous avons opté pour un réseau de neurones récurrents (RNN) de type **LSTM (Long Short-Term Memory)**.

Contrairement aux réseaux simples, le LSTM possède une "cellule mémoire" qui lui permet de retenir des informations sur de longues séquences, ce qui est crucial pour maintenir le rythme et la cohérence de la chorégraphie.

\textbf{Configuration du réseau :}
\begin{itemize}
    \item \textbf{Couche d'entrée :} Taille 34 (correspondant aux 17 points $\times$ 2 coordonnées $x,y$, aplatis en un vecteur 1D).
    \item \textbf{Couches cachées :} 2 couches LSTM empilées avec 256 neurones chacune, permettant de capturer la complexité des mouvements non-linéaires.
    \item \textbf{Couche de sortie :} Une couche linéaire dense de taille 34, qui projette les résultats du LSTM vers les coordonnées de la prochaine pose.
\end{itemize}

L'entraînement a été réalisé avec la fonction de perte \textit{Mean Squared Error} (MSE) pour minimiser la distance euclidienne entre la pose prédite et la pose réelle, optimisée par l'algorithme \textbf{Adam} sur 1000 époques.

\newpage  

\section{Résultats et Visualisations}

Cette section présente l'évaluation des performances du modèle, à la fois sur le plan quantitatif (métriques d'erreur) et qualitatif (cohérence visuelle des mouvements générés).

\subsection{Analyse de l'Apprentissage (Courbe de Loss)}
L'entraînement du réseau LSTM a été réalisé sur 1000 époques. La courbe de perte (\textit{Loss Curve}), représentant l'erreur quadratique moyenne (MSE) entre les prédictions et la réalité, témoigne de la convergence du modèle.

\begin{figure}[h]
    \centering
 
     \includegraphics[width=0.8\textwidth]{loss_curves.png}
    \caption{Courbe d'apprentissage : Évolution de la perte (Loss) sur les jeux d'entraînement (bleu) et de validation (orange).}
    \label{fig:loss}
\end{figure}

Comme illustré par la Figure \ref{fig:loss}, nous observons une chute rapide de l'erreur durant les 100 premières époques, indiquant que le réseau apprend rapidement la structure globale du squelette. La courbe se stabilise ensuite, phase durant laquelle le modèle affine les micro-mouvements spécifiques au style "Égyptien". L'absence de divergence majeure entre les courbes de \textit{Train} et de \textit{Validation} suggère que le modèle ne souffre pas de sur-apprentissage (\textit{overfitting}) excessif.

\subsection{Performance du Modèle (Score $R^2$)}
Pour valider mathématiquement la précision des prédictions, nous avons calculé le coefficient de détermination ($R^2$) sur une séquence de test alignée (sans inversion miroir).

\begin{itemize}
    \item \textbf{Résultat obtenu :} Le modèle atteint un score $R^2$ satisfaisant (généralement supérieur à 0.70 sur les séquences courtes), ce qui signifie qu'il est capable d'anticiper la trajectoire des membres avec une bonne fidélité par rapport à la vidéo originale.
    \item \textbf{Limitation :} Il est important de noter que ce score chute naturellement lorsque le "Mode Miroir" est activé, car le modèle génère alors une trajectoire volontairement différente de la vérité terrain pour créer de la nouveauté.
\end{itemize}

\subsection{Génération Visuelle et Mode Miroir}
L'objectif final étant la création artistique, l'évaluation visuelle est primordiale. Le générateur est capable de produire une séquence continue de 120 frames (ou plus).

L'intégration du \textbf{"Mode Miroir"} (inversion latérale périodique) a permis de briser la monotonie de l'apprentissage. Au lieu de répéter la séquence apprise en boucle, le danseur virtuel alterne entre le mouvement original et son symétrique. Visuellement, cela se traduit par une chorégraphie fluide qui semble "improviser" tout en respectant les contraintes géométriques angulaires de la danse égyptienne (coudes pliés, profil 2D).

\begin{figure}[h]
    \centering
    \includegraphics[width=0.3\textwidth]{skeleton_pose.png}
    \caption{Visualisation d'une pose générée : Le modèle respecte bien la géométrie angulaire typique de la danse.}
    \label{fig:skeleton}
\end{figure}

\subsection{Analyse de l'Espace Latent (PCA)}
Pour vérifier si les mouvements générés appartiennent au même "univers" que la danse réelle, nous avons projeté les données de dimension 34 (17 points $\times$ 2) vers un espace 2D via une Analyse en Composantes Principales (PCA).

La projection montre une forte superposition entre le nuage de points des données réelles et celui des données générées. Cela confirme que le LSTM n'invente pas des poses aberrantes (bruit), mais navigue bien dans l'espace des poses possibles appris lors de l'entraînement. Les trajectoires fluides dans cet espace réduit confirment la continuité temporelle de la génération.

\newpage


\section{Discussion et Pistes d'amélioration}

Ce projet a permis de démontrer la faisabilité de la génération de chorégraphies par réseaux de neurones récurrents. Cependant, l'analyse des résultats met en lumière des défis techniques spécifiques liés à la nature biologique du mouvement.

\subsection{Le défi de la Dérive d'Échelle (\textit{Scale Drift})}
La principale limitation rencontrée lors de nos expérimentations a été le phénomène de "dérive d'échelle". Le modèle LSTM prédit la position des points clés de manière indépendante ou corrélée localement, mais il ne possède pas de connaissance intrinsèque de l'anatomie humaine (longueur fixe des os).

Lors de la génération de longues séquences (supérieures à 60 frames), nous avons observé que les erreurs infimes s'accumulaient, provoquant un grandissement ou un rétrécissement progressif du danseur virtuel. Ce phénomène s'explique par le fait que le modèle prédit des déplacements relatifs : une légère surestimation systématique de la vitesse d'extension des membres conduit à une "explosion" de la taille du squelette sur le long terme.

\subsection{Solution Apportée : Normalisation Anatomique}
Pour pallier ce problème, nous avons implémenté une étape de post-traitement algorithmique : la **Normalisation Globale**.
Au lieu de contraindre chaque os individuellement (ce qui créait des ruptures dans le mouvement), nous avons opté pour une approche globale :
\begin{enumerate}
    \item Mesure de la taille de référence du squelette à la première frame ($Hauteur_{ref}$).
    \item À chaque étape de génération, calcul du facteur d'échelle $s = Hauteur_{actuelle} / Hauteur_{ref}$.
    \item Redimensionnement homothétique de l'ensemble du squelette pour ramener $s$ à 1.
\end{enumerate}
Cette méthode hybride (Deep Learning pour le mouvement + Algorithme classique pour la contrainte physique) s'est avérée être la solution la plus robuste pour stabiliser la génération.

\subsection{Perspectives Futures}
Pour aller plus loin et dépasser les limites actuelles du LSTM, plusieurs pistes d'amélioration sont envisageables :

\begin{itemize}
    \item \textbf{Architecture Transformer :} Remplacer le LSTM par des architectures basées sur l'attention (Transformers). Ces modèles gèrent mieux les dépendances à très long terme et pourraient éviter la dérive sans avoir besoin de correction manuelle.
    \item \textbf{Intégration Audio :} La danse est indissociable de la musique. Une évolution naturelle du projet serait d'ajouter le signal audio (spectrogramme) en entrée du réseau, pour que le modèle apprenne à synchroniser les mouvements (le "beat") avec la musique.
    \item \textbf{Perte Anatomique (\textit{Bone Length Loss}) :} Intégrer la contrainte de longueur des os directement dans la fonction de coût (Loss) lors de l'entraînement, pour forcer le réseau à apprendre la rigidité du squelette.
\end{itemize}

\section{Conclusion}
En conclusion, ce projet a permis de construire un pipeline complet d'analyse et de génération de mouvements. En partant d'une simple vidéo de la "Danse de l'Égyptien", nous avons réussi à extraire la grammaire gestuelle via MMPose et à la reproduire via un LSTM. Si la fidélité anatomique parfaite reste un défi, l'utilisation combinée du Deep Learning et de contraintes géométriques ouvre des voies prometteuses pour l'assistance à la création chorégraphique.


\newpage
%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%
%
% Ici commencent les annexes :
% 
\appendix

\section{Codes sources}

\label{code 2}
\begin{lstlisting}[caption = Simulation d'une marche aléatoire sans mémoire.]
import numpy as np
import matplotlib.pyplot as pls

n = 100 #nombre de pas
p = 0.5

steps = []
for i in range(n):
    u = np.random.rand() #nombre entre 0 et 1
    step = 1*(u<p) - 1*(u>p) 
    steps.append(step)
\end{lstlisting}

\begin{lstlisting}[caption = Code source pour tracer le graphe simulant la marche aléatoire sans mémoire.]
# Graphique
position = np.cumsum(steps)
pls.plot(position, color="blue")
pls.xlabel("Nombre de pas")
pls.ylabel("Position")
pls.grid()
\end{lstlisting}


\begin{lstlisting}[caption = Code source pour simuler la moyenne du nombre de pas du premier retour à 0.]
# test avec un grand nombre de marches aleatoires
nb_simulations = 10000
valeur_retour_0 = []
grand_nb_pas = 0

for n in range(nb_simulations):
    position_test = 1
    steps_count = 0
    
    while position_test != 0:
        u = np.random.rand()
        step = 1 * (u < p) - 1 * (u > p)  
        position_test += step
        steps_count += 1
        
        # pour eviter une trop longue execution
        if steps_count>10000: 
            grand_nb_pas+=1
            break 
            
    # Stocke le nombre de pas du premier retour a 0
    valeur_retour_0.append(steps_count)  

 # Calcul de la moyenne
val = 0
for i in range(len(valeur_retour_0)):
    val+=valeur_retour_0[i]

moyenne = val / len(valeur_retour_0)
print("Moyenne du nombre de pas pour revenir a 0 :", moyenne)
print("Plus de 10000 pas :",grand_nb_pas)
\end{lstlisting}  



\label{code_marche_elephant} 
\begin{lstlisting}[caption = Modélisation et tracé du graphe d'une marche aléatoire de l'éléphant.]
import random
import matplotlib.pyplot as pls
import numpy as np

n = 100
q = 0.4
p = 0.3 

"""
Pour simplifier la modelisation numerique, on etendra la suite e 0 pour modeliser la position initiale de l'elephant en 0 
"""
sigma_n = [0]

sigma_n.append(random.choices([-1, 1], weights=[1-q, q])[0])

for i in range (1 , n):
    T_n = random.randint(1, i)
    sigma = random.choices([-sigma_n[T_n], sigma_n[T_n]], weights=[1-p, p])[0]
    sigma_n.append(sigma)
    
S_n = np.cumsum(sigma_n)

pls.plot(S_n, color="blue")
pls.xlabel("Temps (n)")
pls.ylabel("Position de l'elephant (S_n)")
pls.grid()
\end{lstlisting}


\newpage




\begin{thebibliography}{}

%%%%%%%%%%%% À REMPLACER PAR VOS RÉFÉRENCES !!! %%%%%%%%%%

\bibitem{ross} ROSS, Sheldon M. Initiation aux probabilités. 4\up{ème} édition. Lausanne : Presses polytechniques et Universitaires Romandes, 2014. 606 p.

\bibitem{schutz} SCHUTZ , G. M., AND TRIMPER , S. Elephants can always remember: Ex- act long-range memory effects in a non-markovian random walk. Physical review. E 70, 045101
(2004)

\bibitem{alain} CAMANES, Alain. Récurrence de marches aléatoires. Notes d'exposé Mathématiques. Nantes : Séminaire du lycée Clémenceau. 12 p



\

\end{thebibliography}




%%%%%%%%%%%%%%%%%%% FIN DU DOCUMENT %%%%%%%%%%%%%%%%%%
\end{document}

